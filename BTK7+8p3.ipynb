{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOs+cLcPRAEpnQ/RX69pws7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PLdRS-cnM99h","executionInfo":{"status":"ok","timestamp":1722337390599,"user_tz":-180,"elapsed":2526,"user":{"displayName":"Efe Baskın","userId":"15895511152312245000"}},"outputId":"5c41e8c1-36a0-4132-b149-2e4785faea4c"},"outputs":[{"output_type":"stream","name":"stdout","text":["değer girin : 2\n","0\n","1\n","1\n","1\n"]}],"source":["x1=0\n","x2=0\n","\n","l1=[x1,x2]\n","l2=[x1,x2+1]\n","l3=[x1+1,x2]\n","l4=[x1+1,x2+1]\n","L=[l1,l2,l3,l4]\n","list1=[]\n","for k in L:\n","  i=0\n","  w1=2\n","  w2=3\n","  count=k[i]*w1+k[i+1]*w2\n","  list1.append(count)\n","t=int(input(\"değer girin : \"))\n","for i in list1:\n","  if i<t:\n","    print(0)\n","  else:\n","    print(1)"]},{"cell_type":"code","source":["X1=(0,0,1,1)\n","X2=(0,1,0,1)\n","W=(2,3)\n","t=int(input(\"değer girin : \"))\n","for i in range(4):\n","  s=X1[i]*W[0]+X2[i]*W[1]\n","  if s<t:\n","    print(0)\n","  else:\n","    print(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"reZgn1JkTNsC","executionInfo":{"status":"ok","timestamp":1722337840376,"user_tz":-180,"elapsed":2907,"user":{"displayName":"Efe Baskın","userId":"15895511152312245000"}},"outputId":"96fdaf97-ff0e-43cb-c836-199b1e66e0b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["değer girin : 3\n","0\n","1\n","0\n","1\n"]}]},{"cell_type":"markdown","source":["Hebb Öğrenme Kuralı : iki nöron aynı işarete sahipse ağırlık değeri arttırılır.girişte tüm değerlerin be biasın ağırlığı 0 ayarlanır."],"metadata":{"id":"gQ_8N9S1XALP"}},{"cell_type":"markdown","source":["\n","\n","Aktivasyon Fonksiyonları\n","---\n","\n","*   Binary Step aktivasyon fonksiyonu : 0 dan küçük değerlere 0 ; 0'a eşit ve büyük değerler için 1 döndürür\n","*   Sign aktivasyon fonksiyonu : 0 ise 0 ; 0 dan küçükse -1 ; 0 dan büyükse 1\n","\n","\n","*   Piece-Wise aktivasyon fonksiyonu\n","*   Sigmoid fonksiyonu : Binary classificationda iyi çalışır.0 1 arası çıktı verir\n","*   Tanh aktivasyon fonksiyonu : -1,1 arası değer döndürür.Biraz hantaldır.\n","\n","\n","*   Relu aktivasyon fonksiyonu : -sonsuz ile 0 arasındaki değerler = 0 , 0dan büyük değerler için değer=değer\n","\n","*   Leaky relu : nöron ölümü durumunda kullanılabilir\n","\n","*   Softplus = f(x)=ln(1+e^x)\n","*   Softmax fonksiyonu = Multiclass Classification için uygundur.Çıkıtları olasık olarak verir.Olasık toplamı 1'dir\n","\n","\n","\n"],"metadata":{"id":"7I1lG0uSaIhb"}},{"cell_type":"markdown","source":["Loss Function : Gradient Descent çok güçlü ve çok genel optimizasyon metodudur.\n"],"metadata":{"id":"n1mN43-okJ8-"}},{"cell_type":"markdown","source":["Optimizasyon Fonksiyonları\n","---\n","\n","\n","\n","*   Gradient Descent\n","1.   Dezavantajları:Lokal minimuma düşebilme , daha yavaş öğrenir\n","2.   Avantajları:Minimum noktaya kararlı yakınsama yapar.Vektörleşme yararları kullanılabilir.küçük veri setlerinde güzel çalışır.\n","\n","*   Stochastic Gradient Descent : Local minimuma düşme ihtimali daha düşüktür.Rastgele bir örneklem kulanılır.Büyük veri setlerinde minimuma daha hızlı ulaşır.Daha fazla iterasyona ihtiyaç duyar.\n","\n","*   MiniBatch Gradient Descent : daha hızlı ve kararlı yakınsana sağlar.Hızlı öğrenir.Hiper parametre yapılandırmasına ihtiyaç duyar.\n","\n","\n","*   RMSprop : RMSprop optimizasyonu dikey olarak meydana gelen salınımları minimalize eder. Dolayısıyla öğrenme oranını arttırarak yatay boyutta daha hızlı hareket ederek minimuma daha hızlı ulaşma imkanı elde eder.\n","-Avantajları:\n","1. Büyük verisetlerinde çok iyi çalışır.Daha büyük öğrenme oranları kullanmak mümkündür\n","2. Daha büyük öğrenme oranları elde etmek mümkündür.\n","*   Adam optimizasyonu\n","1.   Yaygın kullanılır.RMSproptan daha iyi çalışabilir.\n","2.   Avantajları :\n","3.   Uygulaması kolay.\n","4.   Küçük Hafıza gereksinimlerine ihtiyaç duyar.\n","5.   Gürültülü veri setleri için uygundur.\n","6.  Hesaplama açısından de verimli bir algoritmadır\n","* Adagrad optimizasyonu\n","1. NLP ve Görüntü işleme için uygundur\n","2. öğrenme oranını manuel olarak ayarlama ihtiyacını ortadan kaldırır\n","3. adımın boyutuna çok duyarlı değildir\n","4. Basit SGD'den daha hızlı ve daha güvenilirdir\n","5. Öğrenme oranını agresif şekilde küçültür\n","6. Hesaplama açısından de verimli bir algoritmadır\n","* Adadelta optimizasyonu\n","1. Agresif öğrenme düşüşünün önüne geçmeye çalışır\n","\n","Momentum\n","----\n","Momentum gradyan azalmadan hemen her zaman daha hızlı çalışır , modele fazladan hiper parametreler girmiş olur.Düzenli şekilde hedefe ulaşmayı hedefler.\n","\n","\n"],"metadata":{"id":"hs4chshSj-dO"}},{"cell_type":"markdown","source":["Perceptron Öğrenme\n","---\n","Amacı pozitif girdileri doğru sınıflandırabilen bir karar çizgi oluşturmaktadır.\n","Lineer olmayan veri noktalarını sınıflandıramaz.\n","*  Bias : Sabit değerdir.Sürecin devam etmesini sağlar\n","\n"],"metadata":{"id":"MxErwz-4qs4j"}},{"cell_type":"code","source":["import numpy as np\n","import math\n","import random"],"metadata":{"id":"hXdssXA-rDZq","executionInfo":{"status":"ok","timestamp":1722411997845,"user_tz":-180,"elapsed":459,"user":{"displayName":"Efe Baskın","userId":"15895511152312245000"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["x=[[1,1,1],\n","   [1,0,1],\n","   [0,1,1],\n","   [0,0,1]]\n","\n","w=[0,0,0]\n","y=[1,0,0,0]\n","lr=0.5\n","for j in range(30):\n","  print(f\"----------------------{j+1}. epoch-----------------------\")\n","  for i in range(4):\n","    u=x[i][0]*w[0]+x[i][1]*w[1]+x[i][2]*w[2]\n","    if u>=0:\n","      u=1\n","    else:\n","      u=0\n","    error=y[i]-u\n","    w[0]=w[0]+lr*error*x[i][0]\n","    w[1]=w[1]+lr*error*x[i][1]\n","    w[2]=w[2]+lr*error*x[i][2]\n","    print(f\"w0 :{w[0]},w1:{w[1]},w2:{w[2]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1BHNNgWv0zyT","executionInfo":{"status":"ok","timestamp":1722415927284,"user_tz":-180,"elapsed":926,"user":{"displayName":"Efe Baskın","userId":"15895511152312245000"}},"outputId":"1c436b60-a09c-48b4-b921-2837acedae43"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------1. epoch-----------------------\n","w0 :0.0,w1:0.0,w2:0.0\n","w0 :-0.5,w1:0.0,w2:-0.5\n","w0 :-0.5,w1:0.0,w2:-0.5\n","w0 :-0.5,w1:0.0,w2:-0.5\n","----------------------2. epoch-----------------------\n","w0 :0.0,w1:0.5,w2:0.0\n","w0 :-0.5,w1:0.5,w2:-0.5\n","w0 :-0.5,w1:0.0,w2:-1.0\n","w0 :-0.5,w1:0.0,w2:-1.0\n","----------------------3. epoch-----------------------\n","w0 :0.0,w1:0.5,w2:-0.5\n","w0 :0.0,w1:0.5,w2:-0.5\n","w0 :0.0,w1:0.0,w2:-1.0\n","w0 :0.0,w1:0.0,w2:-1.0\n","----------------------4. epoch-----------------------\n","w0 :0.5,w1:0.5,w2:-0.5\n","w0 :0.0,w1:0.5,w2:-1.0\n","w0 :0.0,w1:0.5,w2:-1.0\n","w0 :0.0,w1:0.5,w2:-1.0\n","----------------------5. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-0.5\n","w0 :0.0,w1:1.0,w2:-1.0\n","w0 :0.0,w1:0.5,w2:-1.5\n","w0 :0.0,w1:0.5,w2:-1.5\n","----------------------6. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.0\n","w0 :0.5,w1:1.0,w2:-1.0\n","w0 :0.5,w1:0.5,w2:-1.5\n","w0 :0.5,w1:0.5,w2:-1.5\n","----------------------7. epoch-----------------------\n","w0 :1.0,w1:1.0,w2:-1.0\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------8. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------9. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------10. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------11. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------12. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------13. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------14. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------15. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------16. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------17. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------18. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------19. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------20. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------21. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------22. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------23. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------24. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------25. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------26. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------27. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------28. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------29. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","----------------------30. epoch-----------------------\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n","w0 :0.5,w1:1.0,w2:-1.5\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"aB_czbl07PBA"},"execution_count":null,"outputs":[]}]}